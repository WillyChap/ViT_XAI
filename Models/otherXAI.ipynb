{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b03f59d5-43b2-4634-a082-0b4774a12244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import os\n",
    "from baselines.ViT.ViT_explanation_generator import LRP\n",
    "\n",
    "import torch\n",
    "import Simple_ViT.simple_vit_lrp as svitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c3b4dc3-0840-4511-9659-9a5e74ef1180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gradients(inputs, top_pred_idx=None):\n",
    "    \"\"\"Computes the gradients of outputs w.r.t input image.\n",
    "\n",
    "    Args:\n",
    "        inputs: 2D/3D/4D matrix of samples\n",
    "        top_pred_idx: (optional) Predicted label for the x_data\n",
    "                      if classification problem. If regression,\n",
    "                      do not include.\n",
    "\n",
    "    Returns:\n",
    "        Gradients of the predictions w.r.t img_input\n",
    "    \"\"\"\n",
    "    inputs = tf.cast(inputs, tf.float32)\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        tape.watch(inputs)\n",
    "        \n",
    "        # Run the forward pass of the layer and record operations\n",
    "        # on GradientTape.\n",
    "        preds = model(inputs, training=False)  \n",
    "        \n",
    "        # For classification, grab the top class\n",
    "        if top_pred_idx is not None:\n",
    "            preds = preds[:, top_pred_idx]\n",
    "        \n",
    "    # Use the gradient tape to automatically retrieve\n",
    "    # the gradients of the trainable variables with respect to the loss.        \n",
    "    grads = tape.gradient(preds, inputs)\n",
    "    return grads\n",
    "\n",
    "def get_integrated_gradients(inputs, baseline=None, num_steps=50, top_pred_idx=None):\n",
    "    \"\"\"Computes Integrated Gradients for a prediction.\n",
    "\n",
    "    Args:\n",
    "        inputs (ndarray): 2D/3D/4D matrix of samples\n",
    "        baseline (ndarray): The baseline image to start with for interpolation\n",
    "        num_steps: Number of interpolation steps between the baseline\n",
    "            and the input used in the computation of integrated gradients. These\n",
    "            steps along determine the integral approximation error. By default,\n",
    "            num_steps is set to 50.\n",
    "        top_pred_idx: (optional) Predicted label for the x_data\n",
    "                      if classification problem. If regression,\n",
    "                      do not include.            \n",
    "\n",
    "    Returns:\n",
    "        Integrated gradients w.r.t input image\n",
    "    \"\"\"\n",
    "    # If baseline is not provided, start with zeros\n",
    "    # having same size as the input image.\n",
    "    if baseline is None:\n",
    "        input_size = np.shape(inputs)[1:]\n",
    "        baseline = np.zeros(input_size).astype(np.float32)\n",
    "    else:\n",
    "        baseline = baseline.astype(np.float32)\n",
    "\n",
    "    # 1. Do interpolation.\n",
    "    inputs = inputs.astype(np.float32)\n",
    "    interpolated_inputs = [\n",
    "        baseline + (step / num_steps) * (inputs - baseline)\n",
    "        for step in range(num_steps + 1)\n",
    "    ]\n",
    "    interpolated_inputs = np.array(interpolated_inputs).astype(np.float32)\n",
    "\n",
    "    # 3. Get the gradients\n",
    "    grads = []\n",
    "    for i, x_data in enumerate(interpolated_inputs):\n",
    "        grad = get_gradients(x_data, top_pred_idx=top_pred_idx)     \n",
    "        grads.append(grad)\n",
    "    grads = tf.convert_to_tensor(grads, dtype=tf.float32)\n",
    "\n",
    "    # 4. Approximate the integral using the trapezoidal rule\n",
    "    grads = (grads[:-1] + grads[1:]) / 2.0\n",
    "    avg_grads = tf.reduce_mean(grads, axis=0)\n",
    "    # 5. Calculate integrated gradients and return\n",
    "    integrated_grads = (inputs - baseline) * avg_grads\n",
    "    return integrated_grads\n",
    "\n",
    "def random_baseline_integrated_gradients(inputs, num_steps=50, num_runs=5, top_pred_idx=None):\n",
    "    \"\"\"Generates a number of random baseline images.\n",
    "\n",
    "    Args:\n",
    "        inputs (ndarray): 2D/3D/4D matrix of samples\n",
    "        num_steps: Number of interpolation steps between the baseline\n",
    "            and the input used in the computation of integrated gradients. These\n",
    "            steps along determine the integral approximation error. By default,\n",
    "            num_steps is set to 50.\n",
    "        num_runs: number of baseline images to generate\n",
    "        top_pred_idx: (optional) Predicted label for the x_data\n",
    "                      if classification problem. If regression,\n",
    "                      do not include.      \n",
    "\n",
    "    Returns:\n",
    "        Averaged integrated gradients for `num_runs` baseline images\n",
    "    \"\"\"\n",
    "    # 1. List to keep track of Integrated Gradients (IG) for all the images\n",
    "    integrated_grads = []\n",
    "\n",
    "    # 2. Get the integrated gradients for all the baselines\n",
    "    for run in range(num_runs):\n",
    "        baseline = np.zeros(np.shape(inputs)[1:])\n",
    "        for i in np.arange(0,np.shape(baseline)[0]):\n",
    "            j = np.random.choice(np.arange(0,np.shape(inputs)[0]))\n",
    "            baseline[i] = inputs[j,i]\n",
    "\n",
    "        igrads = get_integrated_gradients(\n",
    "            inputs=inputs,\n",
    "            baseline=baseline,\n",
    "            num_steps=num_steps,\n",
    "            top_pred_idx=top_pred_idx)\n",
    "        integrated_grads.append(igrads)\n",
    "\n",
    "    # 3. Return the average integrated gradients for the image\n",
    "    integrated_grads = tf.convert_to_tensor(integrated_grads)\n",
    "    return tf.reduce_mean(integrated_grads, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef724a7d-759a-4d3a-9d0f-9adf875a0960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device available : False\n",
      "device count:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/wchapman/miniconda3.1/envs/MLWPS/lib/python3.11/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No CUDA GPUs are available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice available :\u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available())\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice count: \u001b[39m\u001b[38;5;124m'\u001b[39m, torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count())\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent device: \u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdevice name: \u001b[39m\u001b[38;5;124m'\u001b[39m,torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mget_device_name())\n\u001b[1;32m     13\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/glade/work/wchapman/miniconda3.1/envs/MLWPS/lib/python3.11/site-packages/torch/cuda/__init__.py:769\u001b[0m, in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcurrent_device\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m    768\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns the index of a currently selected device.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 769\u001b[0m     \u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    770\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_cuda_getDevice()\n",
      "File \u001b[0;32m/glade/work/wchapman/miniconda3.1/envs/MLWPS/lib/python3.11/site-packages/torch/cuda/__init__.py:298\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron:\n\u001b[1;32m    297\u001b[0m     os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCUDA_MODULE_LOADING\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLAZY\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 298\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cuda_init\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;66;03m# Some of the queued calls may reentrantly call _lazy_init();\u001b[39;00m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;66;03m# we need to just return without initializing in that case.\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;66;03m# However, we must not let any *other* threads in!\u001b[39;00m\n\u001b[1;32m    302\u001b[0m _tls\u001b[38;5;241m.\u001b[39mis_initializing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No CUDA GPUs are available"
     ]
    }
   ],
   "source": [
    "def set_gpu(gpu_id):\n",
    "    os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_id)\n",
    "gpu_id=0\n",
    "\n",
    "if gpu_id >= 0:\n",
    "    device = \"cuda\"\n",
    "    set_gpu(gpu_id)\n",
    "    print('device available :', torch.cuda.is_available())\n",
    "    print('device count: ', torch.cuda.device_count())\n",
    "    print('current device: ',torch.cuda.current_device())\n",
    "    print('device name: ',torch.cuda.get_device_name())\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "#Additional Info when using cuda\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Usage:')\n",
    "    print('Allocated:', round(torch.cuda.memory_allocated(0)/1024**3,1), 'GB')\n",
    "    print('Cached:   ', round(torch.cuda.memory_reserved(0)/1024**3,1), 'GB')\n",
    "\n",
    "print('using device: ', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a17097-90e1-44cb-b32f-830e895b79c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = 'saved_models/benchmark/model003.pt'\n",
    "model = torch.load(PATH).to(device)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3947a672-5dc2-49e7-9dfc-a95789ecf89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_fil = '/glade/work/wchapman/ViT_XAI/Data_Staging/Mamalakis_Dataset/scp_synth_exm_data.nc'\n",
    "Data_ = xr.open_dataset(dir_fil)\n",
    "Data_train = np.expand_dims(Data_['SSTrand'].isel(time=slice(0,900000)),1)\n",
    "Y_train = np.array(Data_['y'].isel(time=slice(0,900000)))\n",
    "\n",
    "Data_val = np.expand_dims(Data_['SSTrand'].isel(time=slice(950000,1000000)),1)\n",
    "Y_val = np.array(Data_['y'].isel(time=slice(950000,1000000)))\n",
    "\n",
    "Data_test = np.expand_dims(Data_['SSTrand'].isel(time=slice(900000,950000)),1)\n",
    "Y_test = np.array(Data_['y'].isel(time=slice(900000,950000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3872d6ba-5f1f-41ed-98c4-b812b80fd8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.nan_to_num(torch.tensor(Data_val[29475], dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627ef9e2-4852-4fa5-a2eb-f3d139bf230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grad_heatmap = get_gradients((sample.reshape((1,number_inputs)))).numpy()\n",
    "GtI_heatmap = np.multiply(Grad_heatmap1,sample.reshape((1,number_inputs)))\n",
    "IntegratedGrad_zeros_heatmap=get_integrated_gradients(sample.reshape((1,number_inputs))).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1855c3c-9ddc-429c-b05b-7846fec2ec2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.nan_to_num(torch.tensor(Data_val[29475], dtype=torch.float32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLWPS",
   "language": "python",
   "name": "mlwps"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
